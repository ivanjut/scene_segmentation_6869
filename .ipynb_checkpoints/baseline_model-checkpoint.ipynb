{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from torchvision import models, transforms, io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../ADE20K_2021_17_01/'\n",
    "index_file = 'index_ade20k.pkl'\n",
    "with open('{}/{}'.format(DATASET_PATH, index_file), 'rb') as f:\n",
    "    index_ade20k = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_mat = index_ade20k['objectPresence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 150 most common object IDs and non-common object IDs\n",
    "total_object_counts = np.sum(objects_mat, axis=1)\n",
    "object_count_ids = np.argsort(total_object_counts)[::-1]\n",
    "most_common_obj_ids = object_count_ids[:150]\n",
    "irrelevant_obj_ids = object_count_ids[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3049, 2977, 1830, 2854,  311,  773,  470,  400, 1909,  975, 2419,\n",
       "       1450, 3054, 1734,  446, 2683,  349, 1432, 1179, 1394, 2379,  688,\n",
       "        235, 2130, 2376,  788, 1447, 2615,  686, 2310, 1379,  265, 1124,\n",
       "       3034, 1745, 1609,  837,  248,   53, 2137, 2328, 2271,   82, 1205,\n",
       "       1980,  579, 2508, 1237, 1563,   56,  977,  906,  164, 2931, 2275,\n",
       "       1868,  580, 1097, 1935, 1918, 2472, 2242,  100, 2981, 2121,  135,\n",
       "         85, 2177, 2116,  883, 2052, 1427,  258, 2387,  180, 1430, 2119,\n",
       "       2813, 1212, 1275, 1743, 1438, 3086, 2699,   94, 2050,  723, 2529,\n",
       "        145, 2263,  894, 1973, 2577, 2820,  570,  981, 1211, 2835, 2585,\n",
       "       1624, 1348,   76, 1328, 2369, 1929, 2367, 2154,  529, 2678,   41,\n",
       "         63, 3056, 2422,  222,  953, 1614,  377, 2993, 1755, 1787,  912,\n",
       "       2118,  102,  782,  479, 1023, 2675,  211,  119, 2927, 1001, 2272,\n",
       "        917, 2732, 1032,  136, 2530, 2849, 1968, 2340,  729, 2249, 1429,\n",
       "       2345, 2832, 2900, 2879,  775, 1085,  319])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_obj_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find image IDs where no irrelevant objects appear\n",
    "irrelevant_obj_counts = np.sum(objects_mat[irrelevant_obj_ids], axis=0)\n",
    "good_image_ids = np.argwhere(irrelevant_obj_counts == 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   41,    74,   105, ..., 27550, 27556, 27573])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only common objects included\n",
    "common_objects_mat = objects_mat[np.ix_(most_common_obj_ids, good_image_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = []\n",
    "validation_image_ids = []\n",
    "\n",
    "for i in good_image_ids:\n",
    "    if 'training' in index_ade20k['folder'][i]:\n",
    "        train_image_ids.append(i)\n",
    "    elif 'validation' in index_ade20k['folder'][i]:\n",
    "        validation_image_ids.append(i)\n",
    "    else:\n",
    "        raise Exception('Invalid folder name.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_ids, root_dir, index_mat, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_ids (list): list of image IDs from ADE20K\n",
    "            root_dir (string): Directory with all the images.\n",
    "            index_mat (array): object array from index_ade20k.pkl\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            target_transform (callable, optional): Optional transform to be applied\n",
    "                on a sample segmentation label.\n",
    "        \"\"\"\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.index_ade20k = index_mat\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_name = os.path.join(self.root_dir, self.index_ade20k['folder'][image_id], \n",
    "                                self.index_ade20k['filename'][image_id])\n",
    "        img_info = utils.loadAde20K(img_name)\n",
    "        \n",
    "        image = io.read_image(img_info['img_name']).float()\n",
    "        class_mask = Image.fromarray(img_info['class_mask'], mode='I')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(class_mask)\n",
    "            \n",
    "        sample = (image, label)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.CenterCrop(input_size),\n",
    "#                 transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "                transforms.Resize(input_size, interpolation=0),\n",
    "                transforms.CenterCrop(input_size),\n",
    "                transforms.ToTensor()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SegmentationDataset(train_image_ids[:4], '../', index_ade20k, transform=transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([5, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([5, 1, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13d49a550>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images, train_labels = next(iter(train_dataloader))\n",
    "# print(train_images)\n",
    "print(f\"Feature batch shape: {train_images.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_images[2].permute(1,2,0)\n",
    "img /= img.max()\n",
    "label = train_labels[2].squeeze()\n",
    "# label /= label.max()\n",
    "# plt.imshow(np.concatenate([img, label], 1))\n",
    "# plt.imshow(img)\n",
    "for num in label.flatten():\n",
    "    obj_id = num.numpy() - 1\n",
    "    if obj_id not in most_common_obj_ids and obj_id + 1 != 0:\n",
    "        print(\"UH OH: \", obj_id) \n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "../ADE20K_2021_17_01/images/ADE/training/home_or_hotel/bathroom/ADE_train_00000042.jpg\n",
      "[[   0    0    0 ... 2978 2978 2978]\n",
      " [   0    0  774 ... 2978 2978 2978]\n",
      " [   0    0  774 ... 2978 2978 2978]\n",
      " ...\n",
      " [   0    0 2978 ... 2978 2978 2978]\n",
      " [   0    0 2978 ... 2978 2978 2978]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "(536, 402)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in train_image_ids[:1]:\n",
    "    print(i)\n",
    "#     print(index_ade20k['folder'][i], index_ade20k['filename'][i])\n",
    "    full_file_name = '../{}/{}'.format(index_ade20k['folder'][i], index_ade20k['filename'][i])\n",
    "    print(full_file_name)\n",
    "    info = utils.loadAde20K(full_file_name)\n",
    "#     img = cv2.imread(info['img_name'])[:,:,::-1]\n",
    "#     seg = cv2.imread(info['segm_name'])[:,:,::-1]\n",
    "    classmask = info['class_mask']\n",
    "# #     seg_mask = seg.copy()\n",
    "\n",
    "# #     The 0 index in seg_mask corresponds to background (not annotated) pixels\n",
    "# #     seg_mask[info['class_mask'] != obj_id+1] *= 0\n",
    "#     plt.figure(figsize=(10,5))\n",
    "\n",
    "#     plt.imshow(np.concatenate([img, seg], 1))\n",
    "#     plt.axis('off')\n",
    "#     print(img.shape)\n",
    "    print(classmask)\n",
    "    print(classmask.shape)\n",
    "    plt.imshow(classmask)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.segmentation.fcn_resnet50(pretrained=False, num_classes=151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps {obj_ids: 0-149}\n",
    "obj_id_map = {sorted(most_common_obj_ids)[idx]: idx + 1 for idx in range(150)}\n",
    "obj_id_map[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{41: 1,\n",
       " 53: 2,\n",
       " 56: 3,\n",
       " 63: 4,\n",
       " 76: 5,\n",
       " 82: 6,\n",
       " 85: 7,\n",
       " 94: 8,\n",
       " 100: 9,\n",
       " 102: 10,\n",
       " 119: 11,\n",
       " 135: 12,\n",
       " 136: 13,\n",
       " 145: 14,\n",
       " 164: 15,\n",
       " 180: 16,\n",
       " 211: 17,\n",
       " 222: 18,\n",
       " 235: 19,\n",
       " 248: 20,\n",
       " 258: 21,\n",
       " 265: 22,\n",
       " 311: 23,\n",
       " 319: 24,\n",
       " 349: 25,\n",
       " 377: 26,\n",
       " 400: 27,\n",
       " 446: 28,\n",
       " 470: 29,\n",
       " 479: 30,\n",
       " 529: 31,\n",
       " 570: 32,\n",
       " 579: 33,\n",
       " 580: 34,\n",
       " 686: 35,\n",
       " 688: 36,\n",
       " 723: 37,\n",
       " 729: 38,\n",
       " 773: 39,\n",
       " 775: 40,\n",
       " 782: 41,\n",
       " 788: 42,\n",
       " 837: 43,\n",
       " 883: 44,\n",
       " 894: 45,\n",
       " 906: 46,\n",
       " 912: 47,\n",
       " 917: 48,\n",
       " 953: 49,\n",
       " 975: 50,\n",
       " 977: 51,\n",
       " 981: 52,\n",
       " 1001: 53,\n",
       " 1023: 54,\n",
       " 1032: 55,\n",
       " 1085: 56,\n",
       " 1097: 57,\n",
       " 1124: 58,\n",
       " 1179: 59,\n",
       " 1205: 60,\n",
       " 1211: 61,\n",
       " 1212: 62,\n",
       " 1237: 63,\n",
       " 1275: 64,\n",
       " 1328: 65,\n",
       " 1348: 66,\n",
       " 1379: 67,\n",
       " 1394: 68,\n",
       " 1427: 69,\n",
       " 1429: 70,\n",
       " 1430: 71,\n",
       " 1432: 72,\n",
       " 1438: 73,\n",
       " 1447: 74,\n",
       " 1450: 75,\n",
       " 1563: 76,\n",
       " 1609: 77,\n",
       " 1614: 78,\n",
       " 1624: 79,\n",
       " 1734: 80,\n",
       " 1743: 81,\n",
       " 1745: 82,\n",
       " 1755: 83,\n",
       " 1787: 84,\n",
       " 1830: 85,\n",
       " 1868: 86,\n",
       " 1909: 87,\n",
       " 1918: 88,\n",
       " 1929: 89,\n",
       " 1935: 90,\n",
       " 1968: 91,\n",
       " 1973: 92,\n",
       " 1980: 93,\n",
       " 2050: 94,\n",
       " 2052: 95,\n",
       " 2116: 96,\n",
       " 2118: 97,\n",
       " 2119: 98,\n",
       " 2121: 99,\n",
       " 2130: 100,\n",
       " 2137: 101,\n",
       " 2154: 102,\n",
       " 2177: 103,\n",
       " 2242: 104,\n",
       " 2249: 105,\n",
       " 2263: 106,\n",
       " 2271: 107,\n",
       " 2272: 108,\n",
       " 2275: 109,\n",
       " 2310: 110,\n",
       " 2328: 111,\n",
       " 2340: 112,\n",
       " 2345: 113,\n",
       " 2367: 114,\n",
       " 2369: 115,\n",
       " 2376: 116,\n",
       " 2379: 117,\n",
       " 2387: 118,\n",
       " 2419: 119,\n",
       " 2422: 120,\n",
       " 2472: 121,\n",
       " 2508: 122,\n",
       " 2529: 123,\n",
       " 2530: 124,\n",
       " 2577: 125,\n",
       " 2585: 126,\n",
       " 2615: 127,\n",
       " 2675: 128,\n",
       " 2678: 129,\n",
       " 2683: 130,\n",
       " 2699: 131,\n",
       " 2732: 132,\n",
       " 2813: 133,\n",
       " 2820: 134,\n",
       " 2832: 135,\n",
       " 2835: 136,\n",
       " 2849: 137,\n",
       " 2854: 138,\n",
       " 2879: 139,\n",
       " 2900: 140,\n",
       " 2927: 141,\n",
       " 2931: 142,\n",
       " 2977: 143,\n",
       " 2981: 144,\n",
       " 2993: 145,\n",
       " 3034: 146,\n",
       " 3049: 147,\n",
       " 3054: 148,\n",
       " 3056: 149,\n",
       " 3086: 150,\n",
       " -1: 0}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label_arr):\n",
    "    \"\"\"\n",
    "    Encode labels for evaluating loss\n",
    "    label_arr (tensor): B x 1 x H x W\n",
    "    \"\"\"\n",
    "    B, H, W = label_arr.size()[0], label_arr.size()[2], label_arr.size()[3]\n",
    "    encoded_label = np.zeros((B, H, W))\n",
    "    for b in range(B):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                class_id = label_arr[b, 0, h, w].numpy()\n",
    "                new_obj_idx = obj_id_map[class_id - 1]\n",
    "                encoded_label[b, h, w] = new_obj_idx\n",
    "    \n",
    "    return torch.tensor(encoded_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 151, 224, 224])\n",
      "torch.Size([2, 224, 224])\n",
      "LOSS:  tensor(4.0107, grad_fn=<NllLoss2DBackward>)\n",
      "torch.Size([2, 151, 224, 224])\n",
      "torch.Size([2, 224, 224])\n",
      "LOSS:  tensor(3.5756, grad_fn=<NllLoss2DBackward>)\n",
      "Epoch 1 - Training loss: 3.7931636571884155\n",
      "torch.Size([2, 151, 224, 224])\n",
      "torch.Size([2, 224, 224])\n",
      "LOSS:  tensor(2.4530, grad_fn=<NllLoss2DBackward>)\n",
      "torch.Size([2, 151, 224, 224])\n",
      "torch.Size([2, 224, 224])\n",
      "LOSS:  tensor(2.1092, grad_fn=<NllLoss2DBackward>)\n",
      "Epoch 2 - Training loss: 2.2810890674591064\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for i in range(2):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_dataloader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)['out']\n",
    "        print(output.size())\n",
    "        labels = encode_label(labels)\n",
    "        print(labels.size())\n",
    "        loss = criterion(output, labels)\n",
    "        print(\"LOSS: \", loss)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING LOOP DOC (for Eric)\n",
    "Output of running model for each image is (151, 224, 244) - 150 classes + 0 for background, 224 size of image. Currently using batch size 2 for testing, so each generated sample from dataloader is (batchsize, 151, 244, 244)\n",
    "\n",
    "Label is encoded to be a (244, 244) array of class labels. Classes are adapted to fit top 150 and are mapped ID wise via obj_id_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
